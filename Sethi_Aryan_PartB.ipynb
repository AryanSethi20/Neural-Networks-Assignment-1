{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRX6LUnqBpw"
   },
   "source": [
    "CS4001/4042 Assignment 1\n",
    "---\n",
    "Part B, Q1 (15 marks)\n",
    "---\n",
    "\n",
    "Real world datasets often have a mix of numeric and categorical features – this dataset is one example. To build models on such data, categorical features have to be encoded or embedded.\n",
    "\n",
    "PyTorch Tabular is a library that makes it very convenient to build neural networks for tabular data. It is built on top of PyTorch Lightning, which abstracts away boilerplate model training code and makes it easy to integrate other tools, e.g. TensorBoard for experiment tracking.\n",
    "\n",
    "For questions B1 and B2, the following features should be used:   \n",
    "- **Numeric / Continuous** features: dist_to_nearest_stn, dist_to_dhoby, degree_centrality, eigenvector_centrality, remaining_lease_years, floor_area_sqm\n",
    "- **Categorical** features: month, town, flat_model_type, storey_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jA67PbIY3PnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_tabular[extra]\n",
      "  Using cached pytorch_tabular-1.1.1-py2.py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.10/site-packages (from pytorch_tabular[extra]) (2.2.2)\n",
      "Collecting numpy<2.0,>1.20.0 (from pytorch_tabular[extra])\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting pandas>=1.1.5 (from pytorch_tabular[extra])\n",
      "  Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting scikit-learn>=1.3.0 (from pytorch_tabular[extra])\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting pytorch-lightning<2.5.0,>=2.0.0 (from pytorch_tabular[extra])\n",
      "  Using cached pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting omegaconf>=2.3.0 (from pytorch_tabular[extra])\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting torchmetrics<1.6.0,>=0.10.0 (from pytorch_tabular[extra])\n",
      "  Using cached torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorboard!=2.5.0,>2.2.0 (from pytorch_tabular[extra])\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting protobuf<5.29.0,>=3.20.0 (from pytorch_tabular[extra])\n",
      "  Using cached protobuf-5.28.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting pytorch-tabnet==4.1 (from pytorch_tabular[extra])\n",
      "  Using cached pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting PyYAML<6.1.0,>=5.4 (from pytorch_tabular[extra])\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting matplotlib>3.1 (from pytorch_tabular[extra])\n",
      "  Using cached matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting ipywidgets (from pytorch_tabular[extra])\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting einops<0.8.0,>=0.6.0 (from pytorch_tabular[extra])\n",
      "  Using cached einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting rich>=11.0.0 (from pytorch_tabular[extra])\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting wandb<0.19.0,>=0.15.0 (from pytorch_tabular[extra])\n",
      "  Using cached wandb-0.18.7-py3-none-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting plotly<5.25.0,>=5.13.0 (from pytorch_tabular[extra])\n",
      "  Using cached plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting kaleido<0.3.0,>=0.2.0 (from pytorch_tabular[extra])\n",
      "  Using cached kaleido-0.2.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting captum<0.8.0,>=0.5.0 (from pytorch_tabular[extra])\n",
      "  Using cached captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting scipy>1.4 (from pytorch-tabnet==4.1->pytorch_tabular[extra])\n",
      "  Using cached scipy-1.15.2-cp310-cp310-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting tqdm>=4.36 (from pytorch-tabnet==4.1->pytorch_tabular[extra])\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>3.1->pytorch_tabular[extra])\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>3.1->pytorch_tabular[extra])\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>3.1->pytorch_tabular[extra])\n",
      "  Using cached fonttools-4.56.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>3.1->pytorch_tabular[extra])\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (11.1.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>3.1->pytorch_tabular[extra])\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib>3.1->pytorch_tabular[extra]) (2.9.0.post0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.3.0->pytorch_tabular[extra])\n",
      "  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.5->pytorch_tabular[extra])\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.5->pytorch_tabular[extra])\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly<5.25.0,>=5.13.0->pytorch_tabular[extra])\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in ./.venv/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./.venv/lib/python3.10/site-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra]) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached lightning_utilities-0.14.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.0.0->pytorch_tabular[extra])\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich>=11.0.0->pytorch_tabular[extra]) (2.19.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.3.0->pytorch_tabular[extra])\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.0->pytorch_tabular[extra])\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.10/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (75.6.0)\n",
      "Requirement already satisfied: six>1.9 in ./.venv/lib/python3.10/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (1.17.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra])\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.18.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.11.0->pytorch_tabular[extra]) (3.1.6)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in ./.venv/lib/python3.10/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (4.3.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./.venv/lib/python3.10/site-packages (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra]) (7.0.0)\n",
      "Collecting requests<3,>=2.0.0 (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached sentry_sdk-2.22.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached setproctitle-1.3.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.10/site-packages (from ipywidgets->pytorch_tabular[extra]) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets->pytorch_tabular[extra]) (8.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets->pytorch_tabular[extra]) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets->pytorch_tabular[extra])\n",
      "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets->pytorch_tabular[extra])\n",
      "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached aiohttp-3.11.13-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (3.0.50)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.6.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch_tabular[extra])\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch_tabular[extra]) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.11.0->pytorch_tabular[extra]) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached propcache-0.3.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular[extra])\n",
      "  Using cached yarl-1.18.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb<0.19.0,>=0.15.0->pytorch_tabular[extra])\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->pytorch_tabular[extra]) (0.2.3)\n",
      "Using cached pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "Using cached captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Using cached kaleido-0.2.1-py2.py3-none-macosx_11_0_arm64.whl (85.8 MB)\n",
      "Using cached matplotlib-3.10.1-cp310-cp310-macosx_11_0_arm64.whl (8.0 MB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "Using cached protobuf-5.28.3-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
      "Using cached pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached scikit_learn-1.6.1-cp310-cp310-macosx_12_0_arm64.whl (11.1 MB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
      "Using cached wandb-0.18.7-py3-none-macosx_11_0_arm64.whl (15.2 MB)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached pytorch_tabular-1.1.1-py2.py3-none-any.whl (163 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached contourpy-1.3.1-cp310-cp310-macosx_11_0_arm64.whl (253 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached fonttools-4.56.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached grpcio-1.71.0-cp310-cp310-macosx_12_0_universal2.whl (11.3 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Using cached kiwisolver-1.4.8-cp310-cp310-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached lightning_utilities-0.14.0-py3-none-any.whl (28 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached scipy-1.15.2-cp310-cp310-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "Using cached setproctitle-1.3.5-cp310-cp310-macosx_11_0_arm64.whl (11 kB)\n",
      "Using cached aiohttp-3.11.13-cp310-cp310-macosx_11_0_arm64.whl (455 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.5.0-cp310-cp310-macosx_11_0_arm64.whl (52 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached propcache-0.3.0-cp310-cp310-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached yarl-1.18.3-cp310-cp310-macosx_11_0_arm64.whl (92 kB)\n",
      "Installing collected packages: pytz, kaleido, antlr4-python3-runtime, widgetsnbextension, werkzeug, urllib3, tzdata, tqdm, threadpoolctl, tensorboard-data-server, tenacity, smmap, setproctitle, PyYAML, pyparsing, protobuf, propcache, numpy, multidict, mdurl, markdown, lightning-utilities, kiwisolver, jupyterlab-widgets, joblib, idna, grpcio, frozenlist, fonttools, einops, docker-pycreds, cycler, click, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, absl-py, yarl, tensorboard, sentry-sdk, scipy, requests, plotly, pandas, omegaconf, markdown-it-py, gitdb, contourpy, aiosignal, torchmetrics, scikit-learn, rich, matplotlib, ipywidgets, gitpython, aiohttp, wandb, pytorch-tabnet, captum, pytorch-lightning, pytorch_tabular\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed PyYAML-6.0.2 absl-py-2.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.13 aiosignal-1.3.2 antlr4-python3-runtime-4.9.3 async-timeout-5.0.1 attrs-25.3.0 captum-0.7.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 contourpy-1.3.1 cycler-0.12.1 docker-pycreds-0.4.0 einops-0.7.0 fonttools-4.56.0 frozenlist-1.5.0 gitdb-4.0.12 gitpython-3.1.44 grpcio-1.71.0 idna-3.10 ipywidgets-8.1.5 joblib-1.4.2 jupyterlab-widgets-3.0.13 kaleido-0.2.1 kiwisolver-1.4.8 lightning-utilities-0.14.0 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 multidict-6.1.0 numpy-1.26.4 omegaconf-2.3.0 pandas-2.2.3 plotly-5.24.1 propcache-0.3.0 protobuf-5.28.3 pyparsing-3.2.1 pytorch-lightning-2.4.0 pytorch-tabnet-4.1.0 pytorch_tabular-1.1.1 pytz-2025.1 requests-2.32.3 rich-13.9.4 scikit-learn-1.6.1 scipy-1.15.2 sentry-sdk-2.22.0 setproctitle-1.3.5 smmap-5.0.2 tenacity-9.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 threadpoolctl-3.6.0 torchmetrics-1.5.2 tqdm-4.67.1 tzdata-2025.1 urllib3-2.3.0 wandb-0.18.7 werkzeug-3.1.3 widgetsnbextension-4.0.13 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "! pip install \"pytorch_tabular[extra]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jr6P3U7w3NVl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGyEWcVlqKTz"
   },
   "source": [
    "> Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from year 2020 and before as training data, and year 2021 as test data (validation set is not required).\n",
    "**Do not** use data from year 2022 and year 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hoCPcOWupw5Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (159553, 14)\n",
      "Year range: 2017 to 2023\n",
      "Train set (≤2020): 87370 records\n",
      "Test set (2021): 29057 records\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Year range: {df['year'].min()} to {df['year'].max()}\")\n",
    "\n",
    "# Split data by year\n",
    "train_df = df[df['year'] <= 2020]\n",
    "test_df_2021 = df[df['year'] == 2021]\n",
    "\n",
    "print(f\"Train set (≤2020): {train_df.shape[0]} records\")\n",
    "print(f\"Test set (2021): {test_df_2021.shape[0]} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sebMgSuzqPe7"
   },
   "source": [
    "> Refer to the documentation of **PyTorch Tabular** and perform the following tasks: https://pytorch-tabular.readthedocs.io/en/latest/#usage\n",
    "- Use **[DataConfig](https://pytorch-tabular.readthedocs.io/en/latest/data/)** to define the target variable, as well as the names of the continuous and categorical variables.\n",
    "- Use **[TrainerConfig](https://pytorch-tabular.readthedocs.io/en/latest/training/)** to automatically tune the learning rate. Set batch_size to be 1024 and set max_epoch as 50.\n",
    "- Use **[CategoryEmbeddingModelConfig](https://pytorch-tabular.readthedocs.io/en/latest/models/#category-embedding-model)** to create a feedforward neural network with 1 hidden layer containing 50 neurons.\n",
    "- Use **[OptimizerConfig](https://pytorch-tabular.readthedocs.io/en/latest/optimizer/)** to choose Adam optimiser. There is no need to set the learning rate (since it will be tuned automatically) nor scheduler.\n",
    "- Use **[TabularModel](https://pytorch-tabular.readthedocs.io/en/latest/tabular_model/)** to initialise the model and put all the configs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZZWAYdNhqPzh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">551</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:20\u001b[0m,\u001b[1;36m551\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the PyTorch Tabular model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">580</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:20\u001b[0m,\u001b[1;36m580\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">608</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:20\u001b[0m,\u001b[1;36m608\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:20\u001b[0m,\u001b[1;36m678\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">705</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:20\u001b[0m,\u001b[1;36m705\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">842</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:20\u001b[0m,\u001b[1;36m842\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/saved_models exists and is not empty.\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c466fa1f6a4e5186ceb67715e11223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.6918309709189363\n",
      "Restoring states from the checkpoint path at /Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.lr_find_26475eba-be7d-4ceb-8012-682983fc375a.ckpt\n",
      "Restored all states from the checkpoint at /Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.lr_find_26475eba-be7d-4ceb-8012-682983fc375a.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">508</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6918309709189363</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:23\u001b[0m,\u001b[1;36m508\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.6918309709189363\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:23</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">509</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:23\u001b[0m,\u001b[1;36m509\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36b11a6273f482b9ff664a84390a4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">672</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:39\u001b[0m,\u001b[1;36m672\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">23:36:39</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">673</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m23:36:39\u001b[0m,\u001b[1;36m673\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25100b2d1eef40a49ff30b72682a9ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       5156582400.0        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       5156582400.0        </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      5156582400.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      5156582400.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['month', 'town', 'flat_model_type', 'storey_range']\n",
    "continuous_features = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', \n",
    "                      'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n",
    "target = ['resale_price']\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=target,\n",
    "    continuous_cols=continuous_features,\n",
    "    categorical_cols=categorical_features,\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    batch_size=1024,\n",
    "    max_epochs=50\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\",\n",
    "    layers=\"50\"\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "print(\"Training the PyTorch Tabular model...\")\n",
    "tabular_model.fit(train=train_df)\n",
    "\n",
    "results = tabular_model.evaluate(test_df_2021)\n",
    "predictions = tabular_model.predict(test_df_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2UXPKq0qWQG"
   },
   "source": [
    "> Report the test RMSE error and the test R2 value that you obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zmE9Bc7Nqadi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  71809.34567038968\n",
      "R2:  0.8050585528339431\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "rmse_2021 = math.sqrt(mean_squared_error(test_df_2021['resale_price'], predictions['resale_price_prediction']))\n",
    "r2_2021 = r2_score(test_df_2021['resale_price'], predictions['resale_price_prediction'])\n",
    "print(\"RMSE: \", rmse_2021)\n",
    "print(\"R2: \", r2_2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEJhRU18qX22"
   },
   "source": [
    "> Print out the corresponding rows in the dataframe for the top 25 test samples with the largest errors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5ma5K9vKqZEq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lm/rqsmrp091ssch6hl2_m2n0h80000gn/T/ipykernel_36702/786438425.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_2021['predictions'] = predictions['resale_price_prediction']\n",
      "/var/folders/lm/rqsmrp091ssch6hl2_m2n0h80000gn/T/ipykernel_36702/786438425.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df_2021['error'] = (test_df_2021['resale_price'] - test_df_2021['predictions'])**2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>town</th>\n",
       "      <th>full_address</th>\n",
       "      <th>nearest_stn</th>\n",
       "      <th>dist_to_nearest_stn</th>\n",
       "      <th>dist_to_dhoby</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>flat_model_type</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>predictions</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90251</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>454 SIN MING AVENUE</td>\n",
       "      <td>Marymount</td>\n",
       "      <td>1.459009</td>\n",
       "      <td>6.840152</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>EXECUTIVE, Maisonette</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>243.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>1001000.0</td>\n",
       "      <td>1.367026e+06</td>\n",
       "      <td>1.339750e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92405</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>46 SENG POH ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.581977</td>\n",
       "      <td>2.309477</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.166667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>4.417082e+05</td>\n",
       "      <td>1.144414e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112128</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>TAMPINES</td>\n",
       "      <td>156 TAMPINES STREET 12</td>\n",
       "      <td>Tampines</td>\n",
       "      <td>0.370873</td>\n",
       "      <td>12.479752</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>EXECUTIVE, Maisonette</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>998000.0</td>\n",
       "      <td>6.739124e+05</td>\n",
       "      <td>1.050327e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT BATOK</td>\n",
       "      <td>288A BUKIT BATOK STREET 25</td>\n",
       "      <td>Bukit Batok</td>\n",
       "      <td>1.292540</td>\n",
       "      <td>10.763777</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>EXECUTIVE, Apartment</td>\n",
       "      <td>75.583333</td>\n",
       "      <td>144.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>968000.0</td>\n",
       "      <td>6.474819e+05</td>\n",
       "      <td>1.027319e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90608</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>273B BISHAN STREET 24</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.776182</td>\n",
       "      <td>6.297489</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.833333</td>\n",
       "      <td>120.0</td>\n",
       "      <td>37 TO 39</td>\n",
       "      <td>1360000.0</td>\n",
       "      <td>1.043350e+06</td>\n",
       "      <td>1.002673e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92442</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>127D KIM TIAN ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.686789</td>\n",
       "      <td>2.664024</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.333333</td>\n",
       "      <td>113.0</td>\n",
       "      <td>16 TO 18</td>\n",
       "      <td>1165000.0</td>\n",
       "      <td>8.700770e+05</td>\n",
       "      <td>8.697958e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90521</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>237 BISHAN STREET 22</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>6.663943</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>69.583333</td>\n",
       "      <td>121.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>988000.0</td>\n",
       "      <td>6.936112e+05</td>\n",
       "      <td>8.666477e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98379</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>HOUGANG</td>\n",
       "      <td>615 HOUGANG AVENUE 8</td>\n",
       "      <td>Hougang</td>\n",
       "      <td>0.899849</td>\n",
       "      <td>8.828235</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>EXECUTIVE, Apartment</td>\n",
       "      <td>63.666667</td>\n",
       "      <td>142.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>873000.0</td>\n",
       "      <td>5.816306e+05</td>\n",
       "      <td>8.489615e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90432</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>275A BISHAN STREET 24</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>6.370404</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>120.0</td>\n",
       "      <td>25 TO 27</td>\n",
       "      <td>1280000.0</td>\n",
       "      <td>9.891364e+05</td>\n",
       "      <td>8.460161e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88081</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>310A ANG MO KIO AVENUE 1</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.860056</td>\n",
       "      <td>7.263401</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.166667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28 TO 30</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>8.112856e+05</td>\n",
       "      <td>8.335603e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91395</th>\n",
       "      <td>1</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>44 MOH GUAN TERRACE</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.513848</td>\n",
       "      <td>2.313329</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>2 ROOM, Standard</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>67.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>2.240652e+05</td>\n",
       "      <td>8.175868e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112731</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>138A LORONG 1A TOA PAYOH</td>\n",
       "      <td>Braddell</td>\n",
       "      <td>0.461414</td>\n",
       "      <td>4.151360</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>89.833333</td>\n",
       "      <td>114.0</td>\n",
       "      <td>40 TO 42</td>\n",
       "      <td>1238000.0</td>\n",
       "      <td>9.540374e+05</td>\n",
       "      <td>8.063474e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112973</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>138B LORONG 1A TOA PAYOH</td>\n",
       "      <td>Toa Payoh</td>\n",
       "      <td>0.471864</td>\n",
       "      <td>4.101820</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.036944</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>40 TO 42</td>\n",
       "      <td>1240000.0</td>\n",
       "      <td>9.570474e+05</td>\n",
       "      <td>8.006215e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113043</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>TOA PAYOH</td>\n",
       "      <td>139A LORONG 1A TOA PAYOH</td>\n",
       "      <td>Caldecott</td>\n",
       "      <td>0.514517</td>\n",
       "      <td>4.107963</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.023913</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>89.416667</td>\n",
       "      <td>117.0</td>\n",
       "      <td>34 TO 36</td>\n",
       "      <td>1220000.0</td>\n",
       "      <td>9.379340e+05</td>\n",
       "      <td>7.956123e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92533</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>2C BOON TIONG ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.656363</td>\n",
       "      <td>1.982722</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>78.083333</td>\n",
       "      <td>115.0</td>\n",
       "      <td>28 TO 30</td>\n",
       "      <td>1130000.0</td>\n",
       "      <td>8.490399e+05</td>\n",
       "      <td>7.893859e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92340</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>56 HAVELOCK ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.451387</td>\n",
       "      <td>2.128424</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>34 TO 36</td>\n",
       "      <td>1245000.0</td>\n",
       "      <td>9.670102e+05</td>\n",
       "      <td>7.727830e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90193</th>\n",
       "      <td>3</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>446 BRIGHT HILL DRIVE</td>\n",
       "      <td>Marymount</td>\n",
       "      <td>1.231347</td>\n",
       "      <td>6.662305</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>EXECUTIVE, Maisonette</td>\n",
       "      <td>68.083333</td>\n",
       "      <td>243.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>1092888.0</td>\n",
       "      <td>1.369221e+06</td>\n",
       "      <td>7.636000e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92226</th>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>96A HENDERSON ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.586629</td>\n",
       "      <td>2.932814</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>96.750000</td>\n",
       "      <td>113.0</td>\n",
       "      <td>28 TO 30</td>\n",
       "      <td>1220000.0</td>\n",
       "      <td>9.490792e+05</td>\n",
       "      <td>7.339805e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101237</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>KALLANG/WHAMPOA</td>\n",
       "      <td>8 BOON KENG ROAD</td>\n",
       "      <td>Bendemeer</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>2.587444</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.250000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>40 TO 42</td>\n",
       "      <td>1268000.0</td>\n",
       "      <td>1.001042e+06</td>\n",
       "      <td>7.126661e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92443</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>96A HENDERSON ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.586629</td>\n",
       "      <td>2.932814</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>96.583333</td>\n",
       "      <td>113.0</td>\n",
       "      <td>40 TO 42</td>\n",
       "      <td>1256000.0</td>\n",
       "      <td>9.912893e+05</td>\n",
       "      <td>7.007175e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93670</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT TIMAH</td>\n",
       "      <td>6 TOH YI DRIVE</td>\n",
       "      <td>Beauty World</td>\n",
       "      <td>0.428356</td>\n",
       "      <td>8.948410</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>EXECUTIVE, Maisonette</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>154.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>1238000.0</td>\n",
       "      <td>9.755238e+05</td>\n",
       "      <td>6.889375e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90523</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>273B BISHAN STREET 24</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.776182</td>\n",
       "      <td>6.297489</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>120.0</td>\n",
       "      <td>22 TO 24</td>\n",
       "      <td>1260000.0</td>\n",
       "      <td>9.978033e+05</td>\n",
       "      <td>6.874710e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90607</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>273B BISHAN STREET 24</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.776182</td>\n",
       "      <td>6.297489</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.750000</td>\n",
       "      <td>120.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>1208000.0</td>\n",
       "      <td>9.460649e+05</td>\n",
       "      <td>6.860998e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90382</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>251 BISHAN STREET 22</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.081018</td>\n",
       "      <td>6.939944</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>70.166667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>945000.0</td>\n",
       "      <td>6.842034e+05</td>\n",
       "      <td>6.801488e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88413</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>260A ANG MO KIO STREET 21</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.722450</td>\n",
       "      <td>7.861222</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>4 ROOM, Model A</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>93.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>752000.0</td>\n",
       "      <td>4.928863e+05</td>\n",
       "      <td>6.713990e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  year             town                full_address  \\\n",
       "90251       4  2021           BISHAN         454 SIN MING AVENUE   \n",
       "92405      11  2021      BUKIT MERAH            46 SENG POH ROAD   \n",
       "112128     12  2021         TAMPINES      156 TAMPINES STREET 12   \n",
       "90957       6  2021      BUKIT BATOK  288A BUKIT BATOK STREET 25   \n",
       "90608      12  2021           BISHAN       273B BISHAN STREET 24   \n",
       "92442      11  2021      BUKIT MERAH          127D KIM TIAN ROAD   \n",
       "90521      10  2021           BISHAN        237 BISHAN STREET 22   \n",
       "98379      12  2021          HOUGANG        615 HOUGANG AVENUE 8   \n",
       "90432       8  2021           BISHAN       275A BISHAN STREET 24   \n",
       "88081       8  2021       ANG MO KIO    310A ANG MO KIO AVENUE 1   \n",
       "91395       1  2021      BUKIT MERAH         44 MOH GUAN TERRACE   \n",
       "112731      8  2021        TOA PAYOH    138A LORONG 1A TOA PAYOH   \n",
       "112973     11  2021        TOA PAYOH    138B LORONG 1A TOA PAYOH   \n",
       "113043     12  2021        TOA PAYOH    139A LORONG 1A TOA PAYOH   \n",
       "92533      12  2021      BUKIT MERAH          2C BOON TIONG ROAD   \n",
       "92340      10  2021      BUKIT MERAH            56 HAVELOCK ROAD   \n",
       "90193       3  2021           BISHAN       446 BRIGHT HILL DRIVE   \n",
       "92226       9  2021      BUKIT MERAH          96A HENDERSON ROAD   \n",
       "101237     11  2021  KALLANG/WHAMPOA            8 BOON KENG ROAD   \n",
       "92443      11  2021      BUKIT MERAH          96A HENDERSON ROAD   \n",
       "93670      12  2021      BUKIT TIMAH              6 TOH YI DRIVE   \n",
       "90523      10  2021           BISHAN       273B BISHAN STREET 24   \n",
       "90607      12  2021           BISHAN       273B BISHAN STREET 24   \n",
       "90382       7  2021           BISHAN        251 BISHAN STREET 22   \n",
       "88413      12  2021       ANG MO KIO   260A ANG MO KIO STREET 21   \n",
       "\n",
       "         nearest_stn  dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
       "90251      Marymount             1.459009       6.840152           0.016807   \n",
       "92405    Tiong Bahru             0.581977       2.309477           0.016807   \n",
       "112128      Tampines             0.370873      12.479752           0.033613   \n",
       "90957    Bukit Batok             1.292540      10.763777           0.016807   \n",
       "90608         Bishan             0.776182       6.297489           0.033613   \n",
       "92442    Tiong Bahru             0.686789       2.664024           0.016807   \n",
       "90521         Bishan             0.947205       6.663943           0.033613   \n",
       "98379        Hougang             0.899849       8.828235           0.016807   \n",
       "90432         Bishan             0.827889       6.370404           0.033613   \n",
       "88081     Ang Mo Kio             0.860056       7.263401           0.016807   \n",
       "91395    Tiong Bahru             0.513848       2.313329           0.016807   \n",
       "112731      Braddell             0.461414       4.151360           0.016807   \n",
       "112973     Toa Payoh             0.471864       4.101820           0.016807   \n",
       "113043     Caldecott             0.514517       4.107963           0.016807   \n",
       "92533    Tiong Bahru             0.656363       1.982722           0.016807   \n",
       "92340    Tiong Bahru             0.451387       2.128424           0.016807   \n",
       "90193      Marymount             1.231347       6.662305           0.016807   \n",
       "92226    Tiong Bahru             0.586629       2.932814           0.016807   \n",
       "101237     Bendemeer             0.352251       2.587444           0.016807   \n",
       "92443    Tiong Bahru             0.586629       2.932814           0.016807   \n",
       "93670   Beauty World             0.428356       8.948410           0.016807   \n",
       "90523         Bishan             0.776182       6.297489           0.033613   \n",
       "90607         Bishan             0.776182       6.297489           0.033613   \n",
       "90382     Ang Mo Kio             1.081018       6.939944           0.016807   \n",
       "88413     Ang Mo Kio             1.722450       7.861222           0.016807   \n",
       "\n",
       "        eigenvector_centrality        flat_model_type  remaining_lease_years  \\\n",
       "90251                 0.013555  EXECUTIVE, Maisonette              67.666667   \n",
       "92405                 0.047782       3 ROOM, Standard              50.166667   \n",
       "112128                0.000229  EXECUTIVE, Maisonette              61.750000   \n",
       "90957                 0.000217   EXECUTIVE, Apartment              75.583333   \n",
       "90608                 0.015854           5 ROOM, DBSS              88.833333   \n",
       "92442                 0.047782       5 ROOM, Improved              90.333333   \n",
       "90521                 0.015854       5 ROOM, Improved              69.583333   \n",
       "98379                 0.001507   EXECUTIVE, Apartment              63.666667   \n",
       "90432                 0.015854           5 ROOM, DBSS              88.916667   \n",
       "88081                 0.006243       5 ROOM, Improved              90.166667   \n",
       "91395                 0.047782       2 ROOM, Standard              51.083333   \n",
       "112731                0.017995           5 ROOM, DBSS              89.833333   \n",
       "112973                0.036944           5 ROOM, DBSS              89.500000   \n",
       "113043                0.023913           5 ROOM, DBSS              89.416667   \n",
       "92533                 0.047782       5 ROOM, Improved              78.083333   \n",
       "92340                 0.047782       5 ROOM, Improved              90.750000   \n",
       "90193                 0.013555  EXECUTIVE, Maisonette              68.083333   \n",
       "92226                 0.047782       5 ROOM, Improved              96.750000   \n",
       "101237                0.004414           5 ROOM, DBSS              88.250000   \n",
       "92443                 0.047782       5 ROOM, Improved              96.583333   \n",
       "93670                 0.001358  EXECUTIVE, Maisonette              66.666667   \n",
       "90523                 0.015854           5 ROOM, DBSS              88.916667   \n",
       "90607                 0.015854           5 ROOM, DBSS              88.750000   \n",
       "90382                 0.006243       5 ROOM, Improved              70.166667   \n",
       "88413                 0.006243        4 ROOM, Model A              95.500000   \n",
       "\n",
       "        floor_area_sqm storey_range  resale_price   predictions         error  \n",
       "90251            243.0     10 TO 12     1001000.0  1.367026e+06  1.339750e+11  \n",
       "92405             88.0     01 TO 03      780000.0  4.417082e+05  1.144414e+11  \n",
       "112128           148.0     01 TO 03      998000.0  6.739124e+05  1.050327e+11  \n",
       "90957            144.0     10 TO 12      968000.0  6.474819e+05  1.027319e+11  \n",
       "90608            120.0     37 TO 39     1360000.0  1.043350e+06  1.002673e+11  \n",
       "92442            113.0     16 TO 18     1165000.0  8.700770e+05  8.697958e+10  \n",
       "90521            121.0     07 TO 09      988000.0  6.936112e+05  8.666477e+10  \n",
       "98379            142.0     04 TO 06      873000.0  5.816306e+05  8.489615e+10  \n",
       "90432            120.0     25 TO 27     1280000.0  9.891364e+05  8.460161e+10  \n",
       "88081            121.0     28 TO 30     1100000.0  8.112856e+05  8.335603e+10  \n",
       "91395             67.0     01 TO 03      510000.0  2.240652e+05  8.175868e+10  \n",
       "112731           114.0     40 TO 42     1238000.0  9.540374e+05  8.063474e+10  \n",
       "112973           114.0     40 TO 42     1240000.0  9.570474e+05  8.006215e+10  \n",
       "113043           117.0     34 TO 36     1220000.0  9.379340e+05  7.956123e+10  \n",
       "92533            115.0     28 TO 30     1130000.0  8.490399e+05  7.893859e+10  \n",
       "92340            114.0     34 TO 36     1245000.0  9.670102e+05  7.727830e+10  \n",
       "90193            243.0     07 TO 09     1092888.0  1.369221e+06  7.636000e+10  \n",
       "92226            113.0     28 TO 30     1220000.0  9.490792e+05  7.339805e+10  \n",
       "101237           119.0     40 TO 42     1268000.0  1.001042e+06  7.126661e+10  \n",
       "92443            113.0     40 TO 42     1256000.0  9.912893e+05  7.007175e+10  \n",
       "93670            154.0     04 TO 06     1238000.0  9.755238e+05  6.889375e+10  \n",
       "90523            120.0     22 TO 24     1260000.0  9.978033e+05  6.874710e+10  \n",
       "90607            120.0     10 TO 12     1208000.0  9.460649e+05  6.860998e+10  \n",
       "90382            121.0     10 TO 12      945000.0  6.842034e+05  6.801488e+10  \n",
       "88413             93.0     04 TO 06      752000.0  4.928863e+05  6.713990e+10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_2021['predictions'] = predictions['resale_price_prediction']\n",
    "test_df_2021['error'] = (test_df_2021['resale_price'] - test_df_2021['predictions'])**2\n",
    "worst = test_df_2021.sort_values(by=['error'], ascending=False).head(25)\n",
    "best = test_df_2021.sort_values(by=['error'], ascending=True).head(25)\n",
    "worst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q2 (10 marks)\n",
    "---\n",
    "In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-widedeep\n",
      "  Using cached pytorch_widedeep-1.6.5-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas>=1.3.5 in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (2.2.3)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.6 in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (1.26.4)\n",
      "Collecting scipy<=1.12.0,>=1.7.3 (from pytorch-widedeep)\n",
      "  Using cached scipy-1.12.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (112 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (1.6.1)\n",
      "Collecting gensim (from pytorch-widedeep)\n",
      "  Using cached gensim-4.3.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.2 kB)\n",
      "Collecting spacy (from pytorch-widedeep)\n",
      "  Using cached spacy-3.8.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting opencv-contrib-python>=4.9.0.80 (from pytorch-widedeep)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (2.2.2)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (0.17.2)\n",
      "Requirement already satisfied: einops in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (0.7.0)\n",
      "Collecting wrapt (from pytorch-widedeep)\n",
      "  Using cached wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: torchmetrics>=1.3.1 in ./.venv/lib/python3.10/site-packages (from pytorch-widedeep) (1.5.2)\n",
      "Collecting pyarrow>=15.0.0 (from pytorch-widedeep)\n",
      "  Using cached pyarrow-19.0.1-cp310-cp310-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting fastparquet>=2024.2.0 (from pytorch-widedeep)\n",
      "  Using cached fastparquet-2024.11.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting transformers>=4.37.0 (from pytorch-widedeep)\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting sentence-transformers>=2.3.0 (from pytorch-widedeep)\n",
      "  Using cached sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from pytorch-widedeep)\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting cramjam>=2.3 (from fastparquet>=2024.2.0->pytorch-widedeep)\n",
      "  Using cached cramjam-2.9.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from fastparquet>=2024.2.0->pytorch-widedeep) (2025.3.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from fastparquet>=2024.2.0->pytorch-widedeep) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas>=1.3.5->pytorch-widedeep) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas>=1.3.5->pytorch-widedeep) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas>=1.3.5->pytorch-widedeep) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn>=1.0.2->pytorch-widedeep) (3.6.0)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers>=2.3.0->pytorch-widedeep)\n",
      "  Using cached huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.10/site-packages (from sentence-transformers>=2.3.0->pytorch-widedeep) (11.1.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->pytorch-widedeep) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->pytorch-widedeep) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->pytorch-widedeep) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->pytorch-widedeep) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->pytorch-widedeep) (3.1.6)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in ./.venv/lib/python3.10/site-packages (from torchmetrics>=1.3.1->pytorch-widedeep) (0.14.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers>=4.37.0->pytorch-widedeep) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.37.0->pytorch-widedeep)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers>=4.37.0->pytorch-widedeep) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.37.0->pytorch-widedeep)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.37.0->pytorch-widedeep)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim->pytorch-widedeep)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy->pytorch-widedeep)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached murmurhash-1.0.12-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->pytorch-widedeep)\n",
      "  Using cached cymem-2.0.11-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->pytorch-widedeep)\n",
      "  Using cached preshed-3.0.9-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy->pytorch-widedeep)\n",
      "  Using cached thinc-8.3.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy->pytorch-widedeep)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy->pytorch-widedeep)\n",
      "  Using cached srsly-2.5.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy->pytorch-widedeep)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy->pytorch-widedeep)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from spacy->pytorch-widedeep) (75.6.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy->pytorch-widedeep)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy->pytorch-widedeep)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->pytorch-widedeep)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->pytorch-widedeep)\n",
      "  Using cached pydantic_core-2.27.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pytorch-widedeep) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers>=4.37.0->pytorch-widedeep) (2025.1.31)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy->pytorch-widedeep)\n",
      "  Using cached blis-1.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy->pytorch-widedeep)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy->pytorch-widedeep) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy->pytorch-widedeep)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy->pytorch-widedeep) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy->pytorch-widedeep)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->pytorch-widedeep) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=2.0.0->pytorch-widedeep) (1.3.0)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->pytorch-widedeep)\n",
      "  Using cached marisa_trie-1.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->pytorch-widedeep) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->pytorch-widedeep) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->pytorch-widedeep) (0.1.2)\n",
      "Using cached pytorch_widedeep-1.6.5-py3-none-any.whl (22.0 MB)\n",
      "Using cached fastparquet-2024.11.0-cp310-cp310-macosx_11_0_arm64.whl (684 kB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (46.3 MB)\n",
      "Using cached pyarrow-19.0.1-cp310-cp310-macosx_12_0_arm64.whl (30.7 MB)\n",
      "Using cached scipy-1.12.0-cp310-cp310-macosx_12_0_arm64.whl (31.4 MB)\n",
      "Using cached sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Using cached sentencepiece-0.2.0-cp310-cp310-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Using cached gensim-4.3.3-cp310-cp310-macosx_11_0_arm64.whl (24.0 MB)\n",
      "Using cached spacy-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (6.3 MB)\n",
      "Using cached wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cramjam-2.9.1-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Using cached cymem-2.0.11-cp310-cp310-macosx_11_0_arm64.whl (41 kB)\n",
      "Using cached huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp310-cp310-macosx_11_0_arm64.whl (26 kB)\n",
      "Using cached preshed-3.0.9-cp310-cp310-macosx_11_0_arm64.whl (127 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp310-cp310-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp310-cp310-macosx_11_0_arm64.whl (634 kB)\n",
      "Using cached thinc-8.3.4-cp310-cp310-macosx_11_0_arm64.whl (779 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached blis-1.2.0-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Using cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached marisa_trie-1.2.1-cp310-cp310-macosx_11_0_arm64.whl (174 kB)\n",
      "Installing collected packages: sentencepiece, cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, shellingham, scipy, safetensors, regex, pydantic-core, pyarrow, opencv-contrib-python, murmurhash, marisa-trie, cramjam, cloudpathlib, catalogue, blis, annotated-types, srsly, smart-open, pydantic, preshed, language-data, huggingface-hub, typer, tokenizers, langcodes, gensim, fastparquet, confection, weasel, transformers, thinc, spacy, sentence-transformers, pytorch-widedeep\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.2\n",
      "    Uninstalling scipy-1.15.2:\n",
      "      Successfully uninstalled scipy-1.15.2\n",
      "Successfully installed annotated-types-0.7.0 blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cramjam-2.9.1 cymem-2.0.11 fastparquet-2024.11.0 gensim-4.3.3 huggingface-hub-0.29.3 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 opencv-contrib-python-4.11.0.86 preshed-3.0.9 pyarrow-19.0.1 pydantic-2.10.6 pydantic-core-2.27.2 pytorch-widedeep-1.6.5 regex-2024.11.6 safetensors-0.5.3 scipy-1.12.0 sentence-transformers-3.4.1 sentencepiece-0.2.0 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 tokenizers-0.21.1 transformers-4.49.0 typer-0.15.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.metrics import R2Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data（validation set is not required here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (≤2020): 87370 records\n",
      "Test set (≥2021): 72183 records\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "train_df_b2 = df[df['year'] <= 2020].copy()\n",
    "test_df_b2 = df[df['year'] >= 2021].copy()\n",
    "print(f\"Train set (≤2020): {train_df.shape[0]} records\")\n",
    "print(f\"Test set (≥2021): {test_df_b2.shape[0]} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n",
    "https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n",
    "* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n",
    "features and the categorical features. Use this component to transform the training dataset.\n",
    "* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 hidden layers in the MLP, with 200 and 100 neurons respectively.\n",
    "* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 60 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:364: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the PyTorch-WideDeep model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 1366/1366 [00:12<00:00, 105.24it/s, loss=5.54e+10, metrics={'r2': -1.334}] \n",
      "epoch 2: 100%|██████████| 1366/1366 [00:11<00:00, 117.68it/s, loss=1.25e+10, metrics={'r2': 0.4746}]\n",
      "epoch 3: 100%|██████████| 1366/1366 [00:11<00:00, 120.35it/s, loss=7.97e+9, metrics={'r2': 0.6647}]\n",
      "epoch 4: 100%|██████████| 1366/1366 [00:11<00:00, 120.55it/s, loss=5.36e+9, metrics={'r2': 0.7746}]\n",
      "epoch 5: 100%|██████████| 1366/1366 [00:11<00:00, 120.32it/s, loss=4.47e+9, metrics={'r2': 0.8119}]\n",
      "epoch 6: 100%|██████████| 1366/1366 [00:11<00:00, 121.23it/s, loss=4.05e+9, metrics={'r2': 0.8295}]\n",
      "epoch 7: 100%|██████████| 1366/1366 [00:11<00:00, 119.80it/s, loss=3.82e+9, metrics={'r2': 0.8392}]\n",
      "epoch 8: 100%|██████████| 1366/1366 [00:12<00:00, 113.64it/s, loss=3.69e+9, metrics={'r2': 0.8449}]\n",
      "epoch 9: 100%|██████████| 1366/1366 [00:11<00:00, 117.78it/s, loss=3.57e+9, metrics={'r2': 0.8498}]\n",
      "epoch 10: 100%|██████████| 1366/1366 [00:12<00:00, 111.86it/s, loss=3.46e+9, metrics={'r2': 0.8543}]\n",
      "epoch 11: 100%|██████████| 1366/1366 [00:11<00:00, 115.50it/s, loss=3.33e+9, metrics={'r2': 0.8599}]\n",
      "epoch 12: 100%|██████████| 1366/1366 [00:11<00:00, 118.68it/s, loss=3.22e+9, metrics={'r2': 0.8645}]\n",
      "epoch 13: 100%|██████████| 1366/1366 [00:11<00:00, 114.91it/s, loss=3.12e+9, metrics={'r2': 0.8687}]\n",
      "epoch 14: 100%|██████████| 1366/1366 [00:11<00:00, 116.07it/s, loss=3.04e+9, metrics={'r2': 0.8721}]\n",
      "epoch 15: 100%|██████████| 1366/1366 [00:11<00:00, 118.70it/s, loss=2.94e+9, metrics={'r2': 0.8762}]\n",
      "epoch 16: 100%|██████████| 1366/1366 [00:11<00:00, 118.42it/s, loss=2.85e+9, metrics={'r2': 0.8799}]\n",
      "epoch 17: 100%|██████████| 1366/1366 [00:12<00:00, 112.46it/s, loss=2.8e+9, metrics={'r2': 0.882}]  \n",
      "epoch 18: 100%|██████████| 1366/1366 [00:11<00:00, 115.30it/s, loss=2.74e+9, metrics={'r2': 0.8849}]\n",
      "epoch 19: 100%|██████████| 1366/1366 [00:11<00:00, 120.57it/s, loss=2.71e+9, metrics={'r2': 0.886}] \n",
      "epoch 20: 100%|██████████| 1366/1366 [00:12<00:00, 112.62it/s, loss=2.65e+9, metrics={'r2': 0.8886}]\n",
      "epoch 21: 100%|██████████| 1366/1366 [00:12<00:00, 113.69it/s, loss=2.61e+9, metrics={'r2': 0.89}]  \n",
      "epoch 22: 100%|██████████| 1366/1366 [00:12<00:00, 112.77it/s, loss=2.62e+9, metrics={'r2': 0.8898}]\n",
      "epoch 23: 100%|██████████| 1366/1366 [00:11<00:00, 114.22it/s, loss=2.6e+9, metrics={'r2': 0.8908}] \n",
      "epoch 24: 100%|██████████| 1366/1366 [00:11<00:00, 115.88it/s, loss=2.57e+9, metrics={'r2': 0.8918}]\n",
      "epoch 25: 100%|██████████| 1366/1366 [00:11<00:00, 118.71it/s, loss=2.57e+9, metrics={'r2': 0.8918}]\n",
      "epoch 26: 100%|██████████| 1366/1366 [00:11<00:00, 116.38it/s, loss=2.55e+9, metrics={'r2': 0.8925}]\n",
      "epoch 27: 100%|██████████| 1366/1366 [00:11<00:00, 121.12it/s, loss=2.54e+9, metrics={'r2': 0.8932}]\n",
      "epoch 28: 100%|██████████| 1366/1366 [00:11<00:00, 123.62it/s, loss=2.53e+9, metrics={'r2': 0.8938}]\n",
      "epoch 29: 100%|██████████| 1366/1366 [00:11<00:00, 124.05it/s, loss=2.52e+9, metrics={'r2': 0.894}] \n",
      "epoch 30: 100%|██████████| 1366/1366 [00:10<00:00, 124.29it/s, loss=2.51e+9, metrics={'r2': 0.8942}]\n",
      "epoch 31: 100%|██████████| 1366/1366 [00:10<00:00, 126.56it/s, loss=2.52e+9, metrics={'r2': 0.8939}]\n",
      "epoch 32: 100%|██████████| 1366/1366 [00:11<00:00, 122.68it/s, loss=2.51e+9, metrics={'r2': 0.8944}]\n",
      "epoch 33: 100%|██████████| 1366/1366 [00:11<00:00, 117.49it/s, loss=2.5e+9, metrics={'r2': 0.895}]  \n",
      "epoch 34: 100%|██████████| 1366/1366 [00:11<00:00, 123.31it/s, loss=2.48e+9, metrics={'r2': 0.8955}]\n",
      "epoch 35: 100%|██████████| 1366/1366 [00:11<00:00, 123.34it/s, loss=2.47e+9, metrics={'r2': 0.8961}]\n",
      "epoch 36: 100%|██████████| 1366/1366 [00:10<00:00, 125.39it/s, loss=2.47e+9, metrics={'r2': 0.8961}]\n",
      "epoch 37: 100%|██████████| 1366/1366 [00:10<00:00, 127.66it/s, loss=2.45e+9, metrics={'r2': 0.897}] \n",
      "epoch 38: 100%|██████████| 1366/1366 [00:10<00:00, 131.73it/s, loss=2.46e+9, metrics={'r2': 0.8963}]\n",
      "epoch 39: 100%|██████████| 1366/1366 [00:11<00:00, 121.40it/s, loss=2.45e+9, metrics={'r2': 0.8968}]\n",
      "epoch 40: 100%|██████████| 1366/1366 [00:10<00:00, 130.45it/s, loss=2.43e+9, metrics={'r2': 0.8979}]\n",
      "epoch 41: 100%|██████████| 1366/1366 [00:10<00:00, 128.21it/s, loss=2.43e+9, metrics={'r2': 0.8976}]\n",
      "epoch 42: 100%|██████████| 1366/1366 [00:11<00:00, 115.33it/s, loss=2.41e+9, metrics={'r2': 0.8984}]\n",
      "epoch 43: 100%|██████████| 1366/1366 [00:11<00:00, 118.96it/s, loss=2.41e+9, metrics={'r2': 0.8987}]\n",
      "epoch 44: 100%|██████████| 1366/1366 [00:10<00:00, 127.26it/s, loss=2.42e+9, metrics={'r2': 0.8984}]\n",
      "epoch 45: 100%|██████████| 1366/1366 [00:10<00:00, 126.95it/s, loss=2.4e+9, metrics={'r2': 0.8992}] \n",
      "epoch 46: 100%|██████████| 1366/1366 [00:10<00:00, 124.79it/s, loss=2.42e+9, metrics={'r2': 0.8982}]\n",
      "epoch 47: 100%|██████████| 1366/1366 [00:12<00:00, 113.34it/s, loss=2.41e+9, metrics={'r2': 0.8987}]\n",
      "epoch 48: 100%|██████████| 1366/1366 [00:11<00:00, 113.84it/s, loss=2.41e+9, metrics={'r2': 0.8987}]\n",
      "epoch 49: 100%|██████████| 1366/1366 [00:11<00:00, 122.79it/s, loss=2.41e+9, metrics={'r2': 0.8988}]\n",
      "epoch 50: 100%|██████████| 1366/1366 [00:11<00:00, 120.48it/s, loss=2.39e+9, metrics={'r2': 0.8996}]\n",
      "epoch 51: 100%|██████████| 1366/1366 [00:11<00:00, 123.19it/s, loss=2.38e+9, metrics={'r2': 0.8997}]\n",
      "epoch 52: 100%|██████████| 1366/1366 [00:11<00:00, 123.90it/s, loss=2.37e+9, metrics={'r2': 0.9004}]\n",
      "epoch 53: 100%|██████████| 1366/1366 [00:11<00:00, 123.36it/s, loss=2.36e+9, metrics={'r2': 0.9007}]\n",
      "epoch 54: 100%|██████████| 1366/1366 [00:12<00:00, 113.20it/s, loss=2.36e+9, metrics={'r2': 0.9005}]\n",
      "epoch 55: 100%|██████████| 1366/1366 [00:11<00:00, 116.43it/s, loss=2.36e+9, metrics={'r2': 0.9006}]\n",
      "epoch 56: 100%|██████████| 1366/1366 [00:11<00:00, 117.56it/s, loss=2.36e+9, metrics={'r2': 0.9007}]\n",
      "epoch 57: 100%|██████████| 1366/1366 [00:10<00:00, 124.84it/s, loss=2.36e+9, metrics={'r2': 0.9007}]\n",
      "epoch 58: 100%|██████████| 1366/1366 [00:11<00:00, 123.58it/s, loss=2.35e+9, metrics={'r2': 0.9013}]\n",
      "epoch 59: 100%|██████████| 1366/1366 [00:11<00:00, 117.46it/s, loss=2.35e+9, metrics={'r2': 0.9013}]\n",
      "epoch 60: 100%|██████████| 1366/1366 [00:13<00:00, 97.95it/s, loss=2.33e+9, metrics={'r2': 0.902}]  \n"
     ]
    }
   ],
   "source": [
    "tab_preprocessor = TabPreprocessor(\n",
    "    cat_embed_cols=categorical_features,\n",
    "    continuous_cols=continuous_features\n",
    ")\n",
    "\n",
    "X_tab_train = tab_preprocessor.fit_transform(train_df_b2)\n",
    "X_tab_test = tab_preprocessor.transform(test_df_b2)\n",
    "\n",
    "tab_mlp = TabMlp(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    mlp_hidden_dims=[200, 100],\n",
    "    cat_embed_dropout=0.1,\n",
    "    cat_embed_input=tab_preprocessor.cat_embed_input,\n",
    "    continuous_cols=continuous_features\n",
    ")\n",
    "\n",
    "model = WideDeep(deeptabular=tab_mlp)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    objective=\"regression\",\n",
    "    lr=0.001,\n",
    "    metrics=[R2Score],\n",
    "    batch_size=64,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the PyTorch-WideDeep model...\")\n",
    "trainer.fit(\n",
    "    X_tab=X_tab_train,\n",
    "    target=train_df_b2['resale_price'],\n",
    "    n_epochs=60,\n",
    "    batch_size=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Report the test RMSE and the test R2 value that you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 1128/1128 [00:02<00:00, 403.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B2 Results on Test Set (≥2021):\n",
      "RMSE: 101053.34\n",
      "R² Score: 0.6432\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(X_tab=X_tab_test)\n",
    "y_test = test_df_b2['resale_price']\n",
    "rmse_b2 = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2_b2 = r2_score(y_test, preds)\n",
    "\n",
    "print(f\"\\nB2 Results on Test Set (≥2021):\")\n",
    "print(f\"RMSE: {rmse_b2:.2f}\")\n",
    "print(f\"R² Score: {r2_b2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q3 (10 marks)\n",
    "---\n",
    "Besides ensuring that your neural network performs well, it is important to be able to explain the model’s decision. **Captum** is a very handy library that helps you to do so for PyTorch models.\n",
    "\n",
    "Many model explainability algorithms for deep learning models are available in Captum. These algorithms are often used to generate an attribution score for each feature. Features with larger scores are more ‘important’ and some algorithms also provide information about directionality (i.e. a feature with very negative attribution scores means the larger the value of that feature, the lower the value of the output).\n",
    "\n",
    "In general, these algorithms can be grouped into two paradigms:\n",
    "- **perturbation based approaches** (e.g. Feature Ablation)\n",
    "- **gradient / backpropagation based approaches** (e.g. Saliency)\n",
    "\n",
    "The former adopts a brute-force approach of removing / permuting features one by one and does not scale up well. The latter depends on gradients and they can be computed relatively quickly. But unlike how backpropagation computes gradients with respect to weights, gradients here are computed **with respect to the input**. This gives us a sense of how much a change in the input affects the model’s outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in ./.venv/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (from captum) (3.10.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from captum) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.6 in ./.venv/lib/python3.10/site-packages (from captum) (2.2.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from captum) (4.67.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=1.6->captum) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.6->captum) (4.12.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.6->captum) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.6->captum) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.6->captum) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch>=1.6->captum) (2025.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib->captum) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.6->captum) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency, InputXGradient, IntegratedGradients, GradientShap, FeatureAblation, DeepLift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, use the train set (year 2020 and before) and test set (year 2021) following the splits in Question B1 (validation set is not required here). To keep things simple, we will **limit our analysis to numeric / continuous features only**. Drop all categorical features from the dataframes. Standardise the features via **StandardScaler** (fit to training set, then transform all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (87370, 6)\n",
      "Testing data shape: (29057, 6)\n"
     ]
    }
   ],
   "source": [
    "from common_utils import preprocess_dataset\n",
    "\n",
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "train_dataset = df[df['year'] <= 2020].copy()\n",
    "test_dataset = df[df['year'] == 2021].copy()\n",
    "\n",
    "continuous_features = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', \n",
    "                      'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n",
    "target = 'resale_price'\n",
    "\n",
    "# Extract continuous features and target\n",
    "X_train = train_dataset[continuous_features].copy()\n",
    "y_train = train_dataset[target].copy()\n",
    "X_test = test_dataset[continuous_features].copy()\n",
    "y_test = test_dataset[target].copy()\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "X_train_scaled, X_test_scaled = preprocess_dataset(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Follow this tutorial to generate the plot from various model explainability algorithms (https://captum.ai/tutorials/House_Prices_Regression_Interpret).\n",
    "Specifically, make the following changes:\n",
    "- Use a feedforward neural network with 3 hidden layers, each having 5 neurons. Train using Adam optimiser with learning rate of 0.001.\n",
    "- Use Input x Gradients, Integrated Gradients, DeepLift, GradientSHAP, Feature Ablation. To avoid long running time, you can limit the analysis to the first 1000 samples in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/200 - Train Loss: 214808428544.00, Validation Loss: 282384990208.00\n",
      "Epoch 21/200 - Train Loss: 4014323712.00, Validation Loss: 7975342592.00\n",
      "Epoch 41/200 - Train Loss: 3579347200.00, Validation Loss: 7559276544.00\n",
      "Epoch 61/200 - Train Loss: 3475737856.00, Validation Loss: 7328385024.00\n",
      "Epoch 81/200 - Train Loss: 3430372096.00, Validation Loss: 7223565312.00\n",
      "Epoch 101/200 - Train Loss: 3404675328.00, Validation Loss: 7196651520.00\n",
      "Epoch 121/200 - Train Loss: 3381265920.00, Validation Loss: 7232557056.00\n",
      "Epoch 141/200 - Train Loss: 3366855168.00, Validation Loss: 7210760704.00\n",
      "Epoch 161/200 - Train Loss: 3355272960.00, Validation Loss: 7149676544.00\n",
      "Epoch 181/200 - Train Loss: 3348392704.00, Validation Loss: 7308129280.00\n",
      "\n",
      "Model Performance:\n",
      "RMSE: $84950.77\n",
      "R² Score: 0.7272\n"
     ]
    }
   ],
   "source": [
    "class FFNeuralNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FFNeuralNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "datasets = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(datasets, batch_size=64, shuffle=True)\n",
    "\n",
    "model = FFNeuralNet(len(continuous_features))\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, num_epochs=200):\n",
    "    print(\"Training the model...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * len(X_batch)\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_pred = model(X_train_tensor)\n",
    "                train_loss = loss_fn(train_pred, y_train_tensor).item()\n",
    "                val_pred = model(X_test_tensor)\n",
    "                val_loss = loss_fn(val_pred, y_test_tensor).item()\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.2f}, Validation Loss: {val_loss:.2f}\")\n",
    "\n",
    "train_model(model, 200)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor)\n",
    "    test_mse = loss_fn(y_pred, y_test_tensor).item()\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_r2 = r2_score(y_test_tensor.numpy(), y_pred.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance:\n",
      "RMSE: 84950.77\n",
      "R² Score: 0.7272\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"RMSE: {test_rmse:.2f}\")\n",
    "print(f\"R² Score: {test_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing feature attributions with different methods...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_explain_samples = min(1000, X_test_tensor.shape[0])\n",
    "X_subset = X_test_tensor[:n_explain_samples]\n",
    "\n",
    "input_x_gradient = InputXGradient(model)\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "deep_lift = DeepLift(model)\n",
    "gradient_shap = GradientShap(model)\n",
    "feature_ablation = FeatureAblation(model)\n",
    "\n",
    "attributions = {}\n",
    "print(\"\\nComputing feature attributions with different methods...\")\n",
    "\n",
    "attributions['Input x Gradient'] = input_x_gradient.attribute(X_subset).detach().numpy()\n",
    "attributions['Integrated Gradients'] = integrated_gradients.attribute(X_subset, n_steps=50).detach().numpy()\n",
    "attributions['DeepLift'] = deep_lift.attribute(X_subset).detach().numpy()\n",
    "baseline = torch.zeros((1, X_subset.shape[1]))\n",
    "attributions['GradientSHAP'] = gradient_shap.attribute(X_subset, baselines=baseline).detach().numpy()\n",
    "attributions['Feature Ablation'] = feature_ablation.attribute(X_subset).detach().numpy()\n",
    "\n",
    "mean_attributions = {\n",
    "    method: np.abs(attr).mean(axis=0) for method, attr in attributions.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Read the following [descriptions](https://captum.ai/docs/attribution_algorithms) and [comparisons](https://captum.ai/docs/algorithms_comparison_matrix) in Captum to build up your understanding of the difference of various explainability algorithms. Based on your plot, identify the three most important features for regression. Explain how each of these features influences the regression outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top three most important features:\n",
      "1. floor_area_sqm: 93637.0416\n",
      "2. dist_to_dhoby: 49590.1630\n",
      "3. remaining_lease_years: 43499.1142\n",
      "\n",
      "Feature impact direction analysis:\n",
      "- dist_to_nearest_stn: positive correlation with price (avg raw attr: 12930.8172)\n",
      "- dist_to_dhoby: positive correlation with price (avg raw attr: 49480.6567)\n",
      "- degree_centrality: negative correlation with price (avg raw attr: -1292.0199)\n",
      "- eigenvector_centrality: positive correlation with price (avg raw attr: 744.1016)\n",
      "- remaining_lease_years: negative correlation with price (avg raw attr: -13936.4849)\n",
      "- floor_area_sqm: negative correlation with price (avg raw attr: -37378.2451)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 8))\n",
    "x = range(len(continuous_features))\n",
    "width = 0.15\n",
    "offset = 0\n",
    "\n",
    "for i, (method, attr) in enumerate(mean_attributions.items()):\n",
    "    plt.bar([p + offset for p in x], attr, width, label=method)\n",
    "    offset += width\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mean Attribution Score')\n",
    "plt.title('Feature Importance by Explainability Method')\n",
    "plt.xticks([i + 0.3 for i in x], continuous_features, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_attributions.png')\n",
    "plt.show()\n",
    "\n",
    "avg_attributions = np.mean([attr for attr in mean_attributions.values()], axis=0)\n",
    "top_features_idx = np.argsort(avg_attributions)[::-1][:3]\n",
    "top_features = [continuous_features[i] for i in top_features_idx]\n",
    "\n",
    "print(f\"\\nTop three most important features:\")\n",
    "for i, feature in enumerate(top_features):\n",
    "    print(f\"{i+1}. {feature}: {avg_attributions[top_features_idx[i]]:.4f}\")\n",
    "\n",
    "print(\"\\nFeature impact direction analysis:\")\n",
    "for feature_idx, feature in enumerate(continuous_features):\n",
    "    avg_raw_attr = np.mean([attributions[method][:, feature_idx].mean() for method in attributions])\n",
    "    direction = \"positive\" if avg_raw_attr > 0 else \"negative\"\n",
    "    print(f\"- {feature}: {direction} correlation with price (avg raw attr: {avg_raw_attr:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q4 (10 marks)\n",
    "---\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alibi-detect\n",
      "  Downloading alibi_detect-0.12.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (3.10.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (2.2.3)\n",
      "Collecting Pillow<11.0.0,>=5.4.1 (from alibi-detect)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting opencv-python<5.0.0,>=3.2.0 (from alibi-detect)\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (1.12.0)\n",
      "Collecting scikit-image<0.23,>=0.19 (from alibi-detect)\n",
      "  Downloading scikit_image-0.22.0-cp310-cp310-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (1.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.0.0 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (4.49.0)\n",
      "Collecting dill<0.4.0,>=0.3.0 (from alibi-detect)\n",
      "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (2.32.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.8.0 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (2.10.6)\n",
      "Collecting toml<1.0.0,>=0.10.1 (from alibi-detect)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (2.0.10)\n",
      "Collecting numba!=0.54.0,<0.60.0,>=0.50.0 (from alibi-detect)\n",
      "  Downloading numba-0.59.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from alibi-detect) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (2.9.0.post0)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba!=0.54.0,<0.60.0,>=0.50.0->alibi-detect)\n",
      "  Downloading llvmlite-0.42.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2025.1.31)\n",
      "Requirement already satisfied: networkx>=2.8 in ./.venv/lib/python3.10/site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (3.4.2)\n",
      "Collecting imageio>=2.27 (from scikit-image<0.23,>=0.19->alibi-detect)\n",
      "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image<0.23,>=0.19->alibi-detect)\n",
      "  Downloading tifffile-2025.3.13-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in ./.venv/lib/python3.10/site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (3.6.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.29.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers<5.0.0,>=4.0.0->alibi-detect) (2025.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.17.0)\n",
      "Downloading alibi_detect-0.12.0-py3-none-any.whl (381 kB)\n",
      "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
      "Downloading numba-0.59.1-cp310-cp310-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.22.0-cp310-cp310-macosx_12_0_arm64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
      "Downloading llvmlite-0.42.0-cp310-cp310-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tifffile-2025.3.13-py3-none-any.whl (226 kB)\n",
      "Installing collected packages: toml, tifffile, Pillow, opencv-python, llvmlite, dill, numba, imageio, scikit-image, alibi-detect\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.44.0\n",
      "    Uninstalling llvmlite-0.44.0:\n",
      "      Successfully uninstalled llvmlite-0.44.0\n",
      "  Attempting uninstall: numba\n",
      "    Found existing installation: numba 0.61.0\n",
      "    Uninstalling numba-0.61.0:\n",
      "      Successfully uninstalled numba-0.61.0\n",
      "Successfully installed Pillow-10.4.0 alibi-detect-0.12.0 dill-0.3.9 imageio-2.37.0 llvmlite-0.42.0 numba-0.59.1 opencv-python-4.11.0.86 scikit-image-0.22.0 tifffile-2025.3.13 toml-0.10.2\n"
     ]
    }
   ],
   "source": [
    "! pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:1466: DeprecationWarning: `include_input_features` will be deprecated in the next release. Please add index columns to the test dataframe if you want to retain some features like the key or id\n",
      "  warnings.warn(\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_df_2022 = df[df['year'] == 2022].copy() \n",
    "pred_df_2022 = tabular_model.predict(test_df_2022)\n",
    "test_preds_2022 = pred_df_2022[target + \"_prediction\"].values\n",
    "test_actuals_2022 = test_df_2022[target].values\n",
    "rmse_2022 = np.sqrt(mean_squared_error(test_actuals_2022, test_preds_2022))\n",
    "r2_2022 = r2_score(test_actuals_2022, test_preds_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:1466: DeprecationWarning: `include_input_features` will be deprecated in the next release. Please add index columns to the test dataframe if you want to retain some features like the key or id\n",
      "  warnings.warn(\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_df_2023 = df[df['year'] == 2023].copy()\n",
    "pred_df_2023 = tabular_model.predict(test_df_2023)\n",
    "test_preds_2023 = pred_df_2023[target + \"_prediction\"].values\n",
    "test_actuals_2023 = test_df_2023[target].values\n",
    "rmse_2023 = np.sqrt(mean_squared_error(test_actuals_2023, test_preds_2023))\n",
    "r2_2023 = r2_score(test_actuals_2023, test_preds_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Did model degradation occur for the deep learning model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Across Years:\n",
      "2021 - RMSE: 71809.35, R²: 0.8051\n",
      "2022 - RMSE: 125558.47, R²: 0.4562\n",
      "2023 - RMSE: 158672.96, R²: 0.1460\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Performance Across Years:\")\n",
    "print(f\"2021 - RMSE: {rmse_2021:.2f}, R²: {r2_2021:.4f}\")\n",
    "print(f\"2022 - RMSE: {rmse_2022:.2f}, R²: {r2_2022:.4f}\")\n",
    "print(f\"2023 - RMSE: {rmse_2023:.2f}, R²: {r2_2023:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, model degradation occurred. The R2 value dropped from 0.8051 for 2021 test data(in B1) to 0.4562 for 2022 test data, to 0.1460 for 2023 test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2020 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sample shape: (1000, 10)\n",
      "Test sample shape: (1000, 10)\n",
      "Categorical feature indices: [6, 7, 8, 9]\n",
      "\n",
      "Checking for data drift between train (≤2020) and 2023 data...\n",
      "Overall drift detected: [1 0 0 0 1 0 1 0 0 1]\n",
      "\n",
      "Features with significant drift (p-value < 0.05):\n",
      "month: p-value = 0.0000\n",
      "remaining_lease_years: p-value = 0.0000\n",
      "dist_to_nearest_stn: p-value = 0.0106\n",
      "storey_range: p-value = 0.0308\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(SEED)\n",
    "\n",
    "train_drift = df[df['year'] <= 2020].copy()\n",
    "test_drift_2023 = df[df['year'] == 2023].copy()\n",
    "\n",
    "columns_to_use = continuous_features + categorical_features\n",
    "train_drift = train_drift[columns_to_use].copy()\n",
    "test_drift = test_drift_2023[columns_to_use].copy()\n",
    "\n",
    "train_sample = train_drift.sample(1000, random_state=SEED)\n",
    "test_sample = test_drift.sample(min(1000, test_drift.shape[0]), random_state=SEED)\n",
    "\n",
    "print(f\"Train sample shape: {train_sample.shape}\")\n",
    "print(f\"Test sample shape: {test_sample.shape}\")\n",
    "\n",
    "cat_features_idx = [i for i, col in enumerate(columns_to_use) if col in categorical_features]\n",
    "print(f\"Categorical feature indices: {cat_features_idx}\")\n",
    "\n",
    "drift_detector = TabularDrift(\n",
    "    train_sample.values,\n",
    "    p_val=0.05,\n",
    "    categories_per_feature={i: None for i in cat_features_idx}\n",
    ")\n",
    "\n",
    "print(f\"\\nChecking for data drift between train (≤2020) and 2023 data...\")\n",
    "drift_preds = drift_detector.predict(test_sample.values, drift_type='feature')\n",
    "is_drift = drift_preds['data']['is_drift']\n",
    "p_vals = drift_preds['data']['p_val']\n",
    "\n",
    "print(f\"Overall drift detected: {is_drift}\")\n",
    "print(\"\\nFeatures with significant drift (p-value < 0.05):\")\n",
    "\n",
    "feature_scores = dict(zip(columns_to_use, p_vals))\n",
    "drifted_features = {feat: p_val for feat, p_val in feature_scores.items() if p_val < 0.05}\n",
    "for feat, p_val in sorted(drifted_features.items(), key=lambda x: x[1]):\n",
    "    print(f\"{feat}: p-value = {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model degradation occurred due to concept drift. Concept drift happens when the relationship between the input and the output — represented by P(Y|X) — changes, even though the input distribution, P(X), stays the same. Also called posterior shift, this means that while the inputs remain consistent, the way they influence the output shifts. In this situation, government-implemented cooling measures in the housing market have changed how various features relate to the resale price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From your analysis via TabularDrift, which features contribute to this shift?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my analysis above, 'month', 'remaining_lease_years', 'dist_to_nearest_stn' and 'storey_range' have drifted and contributed to the shift. These features have p value <= 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address model degradation in the HDB price prediction model, I implemented a fine-tuning approach that leverages more recent data to update the model's parameters. By retraining the model on combined 2021-2022 data (while preserving the model architecture and learned representations), the approach effectively adapts the model to capture newer market trends and changing relationships between features and housing prices. The results demonstrate remarkable improvement: the model's performance on 2023 data increased from an R² of 0.1460 to 0.7928 (an improvement of 0.6468), while RMSE decreased from 158,672.96 to 78,152.52. This dramatic enhancement illustrates how fine-tuning addresses concept drift in real estate markets, where government cooling measures and shifting economic conditions can rapidly change the pricing dynamics. By incorporating more recent historical data, the model successfully bridges the temporal gap between the original training data and current market conditions, providing much more reliable predictions for current housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Addressing model degradation by fine-tuning the model on recent data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">190</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:07\u001b[0m,\u001b[1;36m190\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:07\u001b[0m,\u001b[1;36m218\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">266</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:07\u001b[0m,\u001b[1;36m266\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">283</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:07\u001b[0m,\u001b[1;36m283\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">297</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:07\u001b[0m,\u001b[1;36m297\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/saved_models exists and is not empty.\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (44) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1ae41143ab4a0ea8298ca093d198b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.8317637711026709\n",
      "Restoring states from the checkpoint path at /Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.lr_find_e664e4f0-3a3a-4f7b-bc80-69b910e15030.ckpt\n",
      "Restored all states from the checkpoint at /Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.lr_find_e664e4f0-3a3a-4f7b-bc80-69b910e15030.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">055</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8317637711026709</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:09\u001b[0m,\u001b[1;36m055\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.8317637711026709\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">057</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:09\u001b[0m,\u001b[1;36m057\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db76fd849e784f1a99d8d9ca646f62fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">235</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:29\u001b[0m,\u001b[1;36m235\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">04:56:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m15\u001b[0m \u001b[1;92m04:56:29\u001b[0m,\u001b[1;36m236\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/tabular_model.py:1466: DeprecationWarning: `include_input_features` will be deprecated in the next release. Please add index columns to the test dataframe if you want to retain some features like the key or id\n",
      "  warnings.warn(\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "/Users/aryansethi/Documents/Personal/Neural-Networks-Assignment-1/.venv/lib/python3.10/site-packages/pytorch_tabular/categorical_encoders.py:71: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAddressing model degradation by fine-tuning the model on recent data...\")\n",
    "\n",
    "fine_tune_df = pd.concat([test_df_2021, test_df_2022])\n",
    "\n",
    "tabular_model.fit(train=fine_tune_df)\n",
    "\n",
    "pred_df_2023_ft = tabular_model.predict(test_df_2023)\n",
    "test_preds_2023_ft = pred_df_2023_ft[target + \"_prediction\"].values\n",
    "rmse_2023_ft = np.sqrt(mean_squared_error(test_actuals_2023, test_preds_2023_ft))\n",
    "r2_2023_ft = r2_score(test_actuals_2023, test_preds_2023_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned Model Performance on 2023 data:\n",
      "Before fine-tuning - RMSE: 158672.96, R²: 0.1460\n",
      "After fine-tuning - RMSE: 78152.52, R²: 0.7928\n",
      "Improvement in R²: 0.6468\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFine-tuned Model Performance on 2023 data:\")\n",
    "print(f\"Before fine-tuning - RMSE: {rmse_2023:.2f}, R²: {r2_2023:.4f}\")\n",
    "print(f\"After fine-tuning - RMSE: {rmse_2023_ft:.2f}, R²: {r2_2023_ft:.4f}\")\n",
    "print(f\"Improvement in R²: {r2_2023_ft - r2_2023:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOG8ZhA98h3O6fnefkjOU9w",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
