{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRX6LUnqBpw"
   },
   "source": [
    "CS4001/4042 Assignment 1\n",
    "---\n",
    "Part B, Q1 (15 marks)\n",
    "---\n",
    "\n",
    "Real world datasets often have a mix of numeric and categorical features – this dataset is one example. To build models on such data, categorical features have to be encoded or embedded.\n",
    "\n",
    "PyTorch Tabular is a library that makes it very convenient to build neural networks for tabular data. It is built on top of PyTorch Lightning, which abstracts away boilerplate model training code and makes it easy to integrate other tools, e.g. TensorBoard for experiment tracking.\n",
    "\n",
    "For questions B1 and B2, the following features should be used:   \n",
    "- **Numeric / Continuous** features: dist_to_nearest_stn, dist_to_dhoby, degree_centrality, eigenvector_centrality, remaining_lease_years, floor_area_sqm\n",
    "- **Categorical** features: month, town, flat_model_type, storey_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jA67PbIY3PnH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_tabular\n",
      "  Downloading pytorch_tabular-1.1.1-py2.py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.13/site-packages (from pytorch_tabular) (2.6.0)\n",
      "Collecting numpy<2.0,>1.20.0 (from pytorch_tabular)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in ./.venv/lib/python3.13/site-packages (from pytorch_tabular) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in ./.venv/lib/python3.13/site-packages (from pytorch_tabular) (1.6.1)\n",
      "Collecting pytorch-lightning<2.5.0,>=2.0.0 (from pytorch_tabular)\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting omegaconf>=2.3.0 (from pytorch_tabular)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting torchmetrics<1.6.0,>=0.10.0 (from pytorch_tabular)\n",
      "  Downloading torchmetrics-1.5.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorboard!=2.5.0,>2.2.0 (from pytorch_tabular)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting protobuf<5.29.0,>=3.20.0 (from pytorch_tabular)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting pytorch-tabnet==4.1 (from pytorch_tabular)\n",
      "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting PyYAML<6.1.0,>=5.4 (from pytorch_tabular)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: matplotlib>3.1 in ./.venv/lib/python3.13/site-packages (from pytorch_tabular) (3.10.1)\n",
      "Collecting ipywidgets (from pytorch_tabular)\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting einops<0.8.0,>=0.6.0 (from pytorch_tabular)\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting rich>=11.0.0 (from pytorch_tabular)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: scipy>1.4 in ./.venv/lib/python3.13/site-packages (from pytorch-tabnet==4.1->pytorch_tabular) (1.15.2)\n",
      "Requirement already satisfied: tqdm>=4.36 in ./.venv/lib/python3.13/site-packages (from pytorch-tabnet==4.1->pytorch_tabular) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib>3.1->pytorch_tabular) (2.9.0.post0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.3.0->pytorch_tabular)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.13/site-packages (from pandas>=1.1.5->pytorch_tabular) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.13/site-packages (from pandas>=1.1.5->pytorch_tabular) (2025.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in ./.venv/lib/python3.13/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in ./.venv/lib/python3.13/site-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (4.12.2)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading lightning_utilities-0.14.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=11.0.0->pytorch_tabular)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=11.0.0->pytorch_tabular) (2.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn>=1.3.0->pytorch_tabular) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.13/site-packages (from scikit-learn>=1.3.0->pytorch_tabular) (3.5.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular)\n",
      "  Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./.venv/lib/python3.13/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (76.0.0)\n",
      "Requirement already satisfied: six>1.9 in ./.venv/lib/python3.13/site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (1.17.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard!=2.5.0,>2.2.0->pytorch_tabular)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->pytorch_tabular) (3.17.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->pytorch_tabular) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->pytorch_tabular) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.venv/lib/python3.13/site-packages (from torch>=1.11.0->pytorch_tabular) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->pytorch_tabular) (1.3.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.13/site-packages (from ipywidgets->pytorch_tabular) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.13/site-packages (from ipywidgets->pytorch_tabular) (9.0.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.13/site-packages (from ipywidgets->pytorch_tabular) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets->pytorch_tabular)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets->pytorch_tabular)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading aiohttp-3.11.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular) (3.0.50)\n",
      "Requirement already satisfied: stack_data in ./.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->pytorch_tabular) (0.6.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch_tabular)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch_tabular) (3.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading attrs-25.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading frozenlist-1.5.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading multidict-6.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading propcache-0.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular)\n",
      "  Downloading yarl-1.18.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->pytorch_tabular) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->pytorch_tabular) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->pytorch_tabular) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->pytorch_tabular) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->pytorch_tabular) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->pytorch_tabular) (0.2.3)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.13/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch_tabular) (3.10)\n",
      "Downloading pytorch_tabular-1.1.1-py2.py3-none-any.whl (163 kB)\n",
      "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
      "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.5.2-py3-none-any.whl (891 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.4/891.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading grpcio-1.71.0-cp313-cp313-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading lightning_utilities-0.14.0-py3-none-any.whl (28 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.13-cp313-cp313-macosx_11_0_arm64.whl (453 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.2.0-py3-none-any.whl (64 kB)\n",
      "Downloading frozenlist-1.5.0-cp313-cp313-macosx_11_0_arm64.whl (50 kB)\n",
      "Downloading multidict-6.1.0-cp313-cp313-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading propcache-0.3.0-cp313-cp313-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading yarl-1.18.3-cp313-cp313-macosx_11_0_arm64.whl (91 kB)\n",
      "Building wheels for collected packages: numpy, antlr4-python3-runtime\n",
      "  Building wheel for numpy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl size=4680104 sha256=5118947ea3e17eaca9451d8dfb7671ee78147a4fd48cad8c71b19424a7a193bb\n",
      "  Stored in directory: /Users/aryansethi/Library/Caches/pip/wheels/8b/2d/9f/b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=2f276156348f2fab7d5d86537913e21a3cebecf9e1ce07a12c3e081bc67e4856\n",
      "  Stored in directory: /Users/aryansethi/Library/Caches/pip/wheels/d5/b3/74/a35b66048c9de6631cd74cbc9475e6feb3e69a467983446bd8\n",
      "Successfully built numpy antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, widgetsnbextension, werkzeug, tensorboard-data-server, PyYAML, protobuf, propcache, numpy, multidict, mdurl, markdown, lightning-utilities, jupyterlab-widgets, grpcio, frozenlist, einops, attrs, aiohappyeyeballs, absl-py, yarl, tensorboard, omegaconf, markdown-it-py, aiosignal, torchmetrics, rich, ipywidgets, aiohttp, pytorch-tabnet, pytorch-lightning, pytorch_tabular\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed PyYAML-6.0.2 absl-py-2.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.13 aiosignal-1.3.2 antlr4-python3-runtime-4.9.3 attrs-25.2.0 einops-0.7.0 frozenlist-1.5.0 grpcio-1.71.0 ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 lightning-utilities-0.14.0 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 multidict-6.1.0 numpy-1.26.4 omegaconf-2.3.0 propcache-0.3.0 protobuf-5.28.3 pytorch-lightning-2.4.0 pytorch-tabnet-4.1.0 pytorch_tabular-1.1.1 rich-13.9.4 tensorboard-2.19.0 tensorboard-data-server-0.7.2 torchmetrics-1.5.2 werkzeug-3.1.3 widgetsnbextension-4.0.13 yarl-1.18.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pytorch_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Jr6P3U7w3NVl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGyEWcVlqKTz"
   },
   "source": [
    "> Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from year 2020 and before as training data, and year 2021 as test data (validation set is not required).\n",
    "**Do not** use data from year 2022 and year 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hoCPcOWupw5Y"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sebMgSuzqPe7"
   },
   "source": [
    "> Refer to the documentation of **PyTorch Tabular** and perform the following tasks: https://pytorch-tabular.readthedocs.io/en/latest/#usage\n",
    "- Use **[DataConfig](https://pytorch-tabular.readthedocs.io/en/latest/data/)** to define the target variable, as well as the names of the continuous and categorical variables.\n",
    "- Use **[TrainerConfig](https://pytorch-tabular.readthedocs.io/en/latest/training/)** to automatically tune the learning rate. Set batch_size to be 1024 and set max_epoch as 50.\n",
    "- Use **[CategoryEmbeddingModelConfig](https://pytorch-tabular.readthedocs.io/en/latest/models/#category-embedding-model)** to create a feedforward neural network with 1 hidden layer containing 50 neurons.\n",
    "- Use **[OptimizerConfig](https://pytorch-tabular.readthedocs.io/en/latest/optimizer/)** to choose Adam optimiser. There is no need to set the learning rate (since it will be tuned automatically) nor scheduler.\n",
    "- Use **[TabularModel](https://pytorch-tabular.readthedocs.io/en/latest/tabular_model/)** to initialise the model and put all the configs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ZZWAYdNhqPzh"
   },
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2UXPKq0qWQG"
   },
   "source": [
    "> Report the test RMSE error and the test R2 value that you obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zmE9Bc7Nqadi"
   },
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEJhRU18qX22"
   },
   "source": [
    "> Print out the corresponding rows in the dataframe for the top 25 test samples with the largest errors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5ma5K9vKqZEq"
   },
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q2 (10 marks)\n",
    "---\n",
    "In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-widedeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.metrics import R2Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data（validation set is not required here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n",
    "https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n",
    "* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n",
    "features and the categorical features. Use this component to transform the training dataset.\n",
    "* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 hidden layers in the MLP, with 200 and 100 neurons respectively.\n",
    "* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 60 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Report the test RMSE and the test R2 value that you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q3 (10 marks)\n",
    "---\n",
    "Besides ensuring that your neural network performs well, it is important to be able to explain the model’s decision. **Captum** is a very handy library that helps you to do so for PyTorch models.\n",
    "\n",
    "Many model explainability algorithms for deep learning models are available in Captum. These algorithms are often used to generate an attribution score for each feature. Features with larger scores are more ‘important’ and some algorithms also provide information about directionality (i.e. a feature with very negative attribution scores means the larger the value of that feature, the lower the value of the output).\n",
    "\n",
    "In general, these algorithms can be grouped into two paradigms:\n",
    "- **perturbation based approaches** (e.g. Feature Ablation)\n",
    "- **gradient / backpropagation based approaches** (e.g. Saliency)\n",
    "\n",
    "The former adopts a brute-force approach of removing / permuting features one by one and does not scale up well. The latter depends on gradients and they can be computed relatively quickly. But unlike how backpropagation computes gradients with respect to weights, gradients here are computed **with respect to the input**. This gives us a sense of how much a change in the input affects the model’s outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import Saliency, InputXGradient, IntegratedGradients, GradientShap, FeatureAblation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, use the train set (year 2020 and before) and test set (year 2021) following the splits in Question B1 (validation set is not required here). To keep things simple, we will **limit our analysis to numeric / continuous features only**. Drop all categorical features from the dataframes. Standardise the features via **StandardScaler** (fit to training set, then transform all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Follow this tutorial to generate the plot from various model explainability algorithms (https://captum.ai/tutorials/House_Prices_Regression_Interpret).\n",
    "Specifically, make the following changes:\n",
    "- Use a feedforward neural network with 3 hidden layers, each having 5 neurons. Train using Adam optimiser with learning rate of 0.001.\n",
    "- Use Input x Gradients, Integrated Gradients, DeepLift, GradientSHAP, Feature Ablation. To avoid long running time, you can limit the analysis to the first 1000 samples in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Read the following [descriptions](https://captum.ai/docs/attribution_algorithms) and [comparisons](https://captum.ai/docs/algorithms_comparison_matrix) in Captum to build up your understanding of the difference of various explainability algorithms. Based on your plot, identify the three most important features for regression. Explain how each of these features influences the regression outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q4 (10 marks)\n",
    "---\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Did model degradation occur for the deep learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2020 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From your analysis via TabularDrift, which features contribute to this shift?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# TODO: \\<Enter your answer here\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOG8ZhA98h3O6fnefkjOU9w",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
